{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:get_checkpoint_dir: result/t3.5_3_3\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'checkpoints/mse_t35_0_bak', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fef6f88f4a8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mse_t35_0_bak/model.ckpt-185000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "current path: 0--Parade\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "current path: 1--Handshaking\n",
      "120\n",
      "130\n",
      "140\n",
      "current path: 10--People_Marching\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "current path: 11--Meeting\n",
      "210\n",
      "220\n",
      "230\n",
      "current path: 12--Group\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "current path: 13--Interview\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "current path: 14--Traffic\n",
      "530\n",
      "540\n",
      "current path: 15--Stock_Market\n",
      "550\n",
      "current path: 16--Award_Ceremony\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "current path: 17--Ceremony\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "current path: 18--Concerts\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "current path: 19--Couple\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "current path: 2--Demonstration\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "current path: 20--Family_Group\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "current path: 21--Festival\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "current path: 22--Picnic\n",
      "1090\n",
      "1100\n",
      "current path: 23--Shoppers\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "current path: 24--Soldier_Firing\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "current path: 25--Soldier_Patrol\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "current path: 26--Soldier_Drilling\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "current path: 27--Spa\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "current path: 28--Sports_Fan\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "current path: 29--Students_Schoolkids\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "current path: 3--Riot\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "current path: 30--Surgeons\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "current path: 31--Waiter_Waitress\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "current path: 32--Worker_Laborer\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "current path: 33--Running\n",
      "1570\n",
      "1580\n",
      "current path: 34--Baseball\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "current path: 35--Basketball\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "current path: 36--Football\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "current path: 37--Soccer\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "current path: 38--Tennis\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "current path: 39--Ice_Skating\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "current path: 4--Dancing\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "current path: 40--Gymnastics\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "current path: 41--Swimming\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "current path: 42--Car_Racing\n",
      "2150\n",
      "2160\n",
      "current path: 43--Row_Boat\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "current path: 44--Aerobics\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "current path: 45--Balloonist\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "current path: 46--Jockey\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "current path: 47--Matador_Bullfighter\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "current path: 48--Parachutist_Paratrooper\n",
      "2390\n",
      "2400\n",
      "current path: 49--Greeting\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "current path: 5--Car_Accident\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "2490\n",
      "current path: 50--Celebration_Or_Party\n",
      "2500\n",
      "2510\n",
      "2520\n",
      "2530\n",
      "2540\n",
      "current path: 51--Dresses\n",
      "2550\n",
      "2560\n",
      "2570\n",
      "2580\n",
      "2590\n",
      "2600\n",
      "2610\n",
      "current path: 52--Photographers\n",
      "2620\n",
      "2630\n",
      "2640\n",
      "2650\n",
      "2660\n",
      "2670\n",
      "current path: 53--Raid\n",
      "2680\n",
      "2690\n",
      "2700\n",
      "2710\n",
      "2720\n",
      "current path: 54--Rescue\n",
      "2730\n",
      "2740\n",
      "2750\n",
      "2760\n",
      "2770\n",
      "current path: 55--Sports_Coach_Trainer\n",
      "2780\n",
      "2790\n",
      "2800\n",
      "2810\n",
      "2820\n",
      "2830\n",
      "current path: 56--Voter\n",
      "2840\n",
      "2850\n",
      "2860\n",
      "2870\n",
      "2880\n",
      "current path: 57--Angler\n",
      "2890\n",
      "2900\n",
      "2910\n",
      "2920\n",
      "current path: 58--Hockey\n",
      "2930\n",
      "2940\n",
      "2950\n",
      "2960\n",
      "current path: 59--people--driving--car\n",
      "2970\n",
      "2980\n",
      "2990\n",
      "3000\n",
      "current path: 6--Funeral\n",
      "3010\n",
      "3020\n",
      "3030\n",
      "3040\n",
      "current path: 61--Street_Battle\n",
      "3050\n",
      "3060\n",
      "3070\n",
      "current path: 7--Cheering\n",
      "3080\n",
      "3090\n",
      "3100\n",
      "3110\n",
      "current path: 8--Election_Campain\n",
      "3120\n",
      "3130\n",
      "3140\n",
      "current path: 9--Press_Conference\n",
      "3150\n",
      "3160\n",
      "3170\n",
      "3180\n",
      "3190\n",
      "3200\n",
      "3210\n",
      "3220\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os, re\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "import tf_extend as tfe\n",
    "\n",
    "from nets.cascadeOut import CascadeOut\n",
    "net = CascadeOut()\n",
    "\n",
    "wider_anno_file = '/home/luojiapeng/datasets/widerface/wider_face_split/wider_face_val_bbx_gt.txt'\n",
    "wider_base_dir = '/home/luojiapeng/datasets/widerface/WIDER_val/images'\n",
    "\n",
    "output_dir = tfe.get_checkpoint_dir('result', 't3.5_3')\n",
    "model_dir = 'checkpoints/mse_t35_0_bak'\n",
    "params = {'thres': 0.5}\n",
    "\n",
    "def get_wider_imgs():\n",
    "    anno_file = open(wider_anno_file, 'r')\n",
    "    fnames = []\n",
    "    for line in anno_file.readlines():\n",
    "        line = line.rstrip()\n",
    "        if re.match('^.*\\.jpg$', line):\n",
    "            fnames.append(line)\n",
    "    return fnames\n",
    "\n",
    "\n",
    "def wider_eval_input_fn():\n",
    "    fnames = get_wider_imgs()\n",
    "    fnames = [os.path.join(wider_base_dir, x) for x in fnames]\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((fnames,))\n",
    "\n",
    "    def fn(fname):\n",
    "        raw_img = tf.read_file(fname)\n",
    "        image = tf.image.decode_jpeg(raw_img, channels=3)\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        return {'fname': fname, 'image': image}\n",
    "\n",
    "    dataset = dataset.map(fn, num_parallel_calls=8)\n",
    "    return dataset\n",
    "\n",
    "def save_wider_result(output_dir, fnames, results):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    current_event = ''\n",
    "    i=-1\n",
    "    for res in results:\n",
    "        i+=1\n",
    "        fname = fnames[i]\n",
    "        bboxes, scores = res['bboxes'], res['scores']\n",
    "        assert len(bboxes) == len(scores)\n",
    "        event = fname.split('/')[0]\n",
    "        if current_event != event:\n",
    "            current_event = event\n",
    "            save_path = os.path.join(output_dir, current_event)\n",
    "            if not os.path.exists(save_path):\n",
    "                os.mkdir(save_path)\n",
    "            print('current path:', current_event)\n",
    "\n",
    "        out_fname = fname.split('.jpg')[0]\n",
    "        out_fname = os.path.join(output_dir, out_fname + '.txt')\n",
    "        fid = open(out_fname, 'w')\n",
    "        fid.write(fname.split('/')[-1] + '\\n')\n",
    "        if bboxes is None:\n",
    "            fid.write(str(1) + '\\n')\n",
    "            fid.write('%f %f %f %f %f\\n' % (0, 0, 0, 0, 0.01))\n",
    "            continue\n",
    "        else:\n",
    "            fid.write(str(len(bboxes)) + '\\n')\n",
    "            for _i in range(len(scores)):\n",
    "                s, b =scores[_i], bboxes[_i]\n",
    "                fid.write('%.2f %.2f %.2f %.2f %.2f\\n' % (b[1], b[0], b[3] - b[1] + 1, b[2] - b[0] + 1, s))\n",
    "\n",
    "            fid.close()\n",
    "            if i % 10 == 0 and i:\n",
    "                print(i)\n",
    "    if i+1 != len(fnames):\n",
    "        raise Exception('length of fnames is not consistent with results')\n",
    "\n",
    "def eval_on_wider():\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    runConfig = tf.estimator.RunConfig(model_dir=model_dir)\n",
    "    classifier = tf.estimator.Estimator(model_fn=net.model_fn,\n",
    "                                        params=params,\n",
    "                                        config=runConfig)\n",
    "    results = classifier.predict(wider_eval_input_fn)\n",
    "    save_wider_result(output_dir, get_wider_imgs(), results)\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "    eval_on_wider()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
